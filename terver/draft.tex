\section{Случайный вектор}

\opred
Пусть случайный опыт \GOFP.
Случайным вектором $\xI$ размерности $n$, наблюдаемым в опыте $G$, называется упорядоченный набор случайных величин, наблюдаемых в данном опыте.

Можно доказать эквивалентность следующего определения:

\opred
Пусть случайный опыт \GOFP.
Случайным вектором $\xI$ размерности $n$, наблюдаемым в опыте $G$, называется функция $\xI:\Omega\to\R^n$, такая,
что $\xI$ $(\calF,\calB_{\R^n})$-измерима, т. е. $\forall(B\in\calB_{\R^n})[\xI^{-1}(B)\in\calF]$.

\opred
Пусть случайный вектор $\xI$ наблюдается в случайном опыте \GOFP.
Распределением случайного вектора $\xI$ называется функция $P_\xI : \calB_{\R^n} \to [0;1]$, определяемая равенством
$$
P_\xI(B)=P(\xI^{-1}(B))
$$

Можно доказать, что $P_\xI$ --- вероятностная мера на $(\R^n,\calB_{\R^n})$.
Этот факт даёт возможность перейти к выборочному вероятностному пространству (аналогично тому, как это было сделано для случайной величины):
$$
\left<\Omega,\calF,P\right> \stackrel{\xI}{\to} \left<\R^n, \calB_{\R^n}, P_\xI\right>
$$
и рассматривать в нём непосредственно заданный случайный вектор $\vec{\eta}(\vec{x})=\vec{x}$.
Легко видеть, что в таком случае $\forall(B\in\calB_{\R^n})\left[P_{\vec{\eta}}(B)=P_\xI(B)\right]$.
%TODO: примеры







\section{Неравенство Маркова}
Пусть $\xi \in L_1(\Omega,\calF,P)$ и $P\{\xi \geq 0\}=1$, $T>0$.
Тогда 
\begin{equation}\label{neravenstvo Markova}
	P\{\xi \geq T\} \leq \frac{M\xi}{T}
\end{equation}

\dokvo
\begin{multline*}
M\xi = \int_{-\infty}^{\infty} x dF_\xi(x) =
\\
\mbox{(т. к. $\xi$ неотрицательна почти наверное)}
\\
=\int_{\{x \geq T\}} x dF_\xi(x) + \int_{\{0 \leq x < T\}} x dF_\xi(x) \geq 
\\
\mbox{(т. к. $F_\xi$ - неубывающая)} \\
\geq \int_{\{x \geq T\}} x dF_\xi(x) \geq \int_{\{x \geq T\}} T dF_\xi(x)
=T\int_{\{x \geq T\}} dF_\xi(x) = \\ =
T \left( \lim_{x\to+\infty} F_\xi(x) - F_\xi(T-)\right) = T P\{\xi\geq T\}
\end{multline*}

\dokno

\section{Неравенство Чебышева}
Пусть $\xi\in l_2(\Omega,\calF,P)$, $\varepsilon>0$.
Тогда
\begin{equation}\label{neravenstvo_Chebysheva}
P\{|\xi-M\xi|\geq\varepsilon\}\leq\frac{D\xi}{\varepsilon^2}
\end{equation}

\dokvo
\begin{multline*}
	P\{|\xi-M\xi|\geq\varepsilon\}=
	P\{|\xi-M\xi|^2\geq\varepsilon^2\}=
	\\\mbox{(положив в неравенстве Маркова (\ref{neravenstvo Markova}) $T=\varepsilon^2$)}\\
	=\frac{M\left((\xi-M\xi)^2\right)}{\varepsilon^2}
	=\frac{D\xi}{\varepsilon^2}
\end{multline*}


\dokno

\section{Закон больших чисел}

\paragraph{Идеология.}
Обычно случайная величина <<размазана>> по числовой оси.
Если случайные величины складывать, то <<размазанность>> будет <<расползаться>>.
Но оказывается, что при определённых условиях среднее арифметическое величин <<расползаться>> не будет.

\begin{teorema}
Пусть $\left\{\xi_k\right\}_{k=1}^\infty$ --- последовательность стохастически независимых интегрируемых с квадратом случайных величин, дисперсия которых ограничена в совокупности, т. е.
$$
\forall(k\in\N)\left[\xi_k\in L_2(\Omega,\calF,P)\right]
$$
$$
\exists(C>0)\forall(k\in\N)\left[ D\xi_k \leq C \right]
$$

Обозначим $\bar{\xi}_n := \frac{1}{n}\suml_{k=1}^n \xi_k$,
$\bar{\mu}_n := \frac{1}{n}\suml_{k=1}^n M\xi_k$


Тогда 
\begin{equation*}
	\forall(\varepsilon>0)\left[P(|\bar{\xi}_n - \bar{\mu}_n| \geq \varepsilon) \xrightarrow[n\to\infty]{} 0\right]
\end{equation*}
\end{teorema}

\dokvo
\begin{multline*}
	P\{|\bar{\xi}_n-\bar{\mu}_n |\geq \varepsilon\} =
	\\ \mbox{(т. к. $\bar{\mu}_n=M\bar{\xi}_n$)} \\
	=P\{|\bar\xi_n - M\bar\xi_n|\geq \varepsilon\}\leq
	\\\mbox{(применяем неравенство Чебышева (\ref{neravenstvo_Chebysheva}))}\\
	\leq \frac{D\bar\xi_n}{\varepsilon^2}
	=\frac{D\left(\frac{1}{n}\suml_{k=1}^n \xi_k\right)}{\varepsilon^2}
	=\frac{\frac{1}{n^2}D\left(\suml_{k=1}^n \xi_k\right)}{\varepsilon^2}
	=\\\mbox{(в силу стохастической независимости дисперсия аддитивна)}\\
	=\frac{\frac{1}{n^2}\left(\suml_{k=1}^n D\xi_k\right)}{\varepsilon^2}
	\leq \frac{\frac{1}{n^2}\left(\suml_{k=1}^n C\right)}{\varepsilon^2}
	= \frac{nC}{n^2 \varepsilon^2}
	= \frac{C}{n \varepsilon^2}
	\xrightarrow[n\to\infty]{} 0
\end{multline*}
\dokno

\opred
Пусть $\{\xi_k\}_{k=1}^\infty$ --- последовательность случайных величин, наблюдаемых в опыте \GOFP,
$\xi$ --- также случайная величина, наблюдаемая в этом опыте.
Говорят, что $\xi_k$ сходится по вероятности к $\xi$ и пишут:
$$
\xi_k \xrightarrow[n\to\infty]{P} \xi
$$
если
$$
\forall(\varepsilon>0)\left[P\{|\xi_n-\xi|\geq \varepsilon\}\xrightarrow[n\to\infty]{}0\right]
$$

Сформулируем теперь следствие из закона больших чисел --- в случае, когда мы имеем дело с последовательностью одинаково распределённых случайных величин.

\begin{sledstvie}
Рассмотрим последовательность одинаково распределённых интегрируемых с квадратом случайных величин $\{\xi_k\}_{k=1}^\infty$, наблюдаемых в случайном опыте \GOFP.
Обозначим $M\xi_k=\mu$, $D\xi_k=\sigma^2$.
Тогда $\bar\xi_n \xrightarrow[n\to\infty]{P}\mu$.
\end{sledstvie}

Рассмотрим теперь схему Бернулли.

\begin{sledstvie} (теорема Бернулли)
Частота появления события при неограниченном увеличении количества независимых повторений одного и того же опыта по вероятности сходится к вероятности данного события.
Переформулируем строго.

Пусть к \GOFP применена схема Бернулли с вероятностью успеха $p$ и количеством повторений $n$.
Обозначим через $\nu_n$ количество успехов в $n$ опытах.
Тогда $\frac{\nu_n}{n}\xrightarrow[n\to\infty]{P}p$.
\end{sledstvie}

\dokvo
Пусть случайная величина $\xi_k$ равна 1, если в $k$-м опыте произошёл успех, и 0 в противном случае.
Очевидно, что $\xi_k$ стохастически независимы и распределены одинаково.
Заметим, что $\nu_n=\suml_{k=1}^n \xi_k$.
Более того, $\bar\xi_n = \frac{\nu_n}{n}$, $M\xi_k=p$.
Применив следствие 1 из закона больших чисел, получим требуемое.
\dokno

\section{Центральная предельная теорема}

Закон больших чисел и следствия из него позволяют судить о поведении среднего арифметического последовательности одинаково распределённых случайных величин, т. е. сумма величин (обратите внимание, <<сдвинутых>> на матожидание) делится на $n$, благодаря чему и стабилизируется.
Возникает закономерный вопрос: а что будет, если делить не на первую степень $n$, а на небольшую положительную?
Ответ для случая степени, равной $\frac{1}{2}$, и даёт центральная предельная теорема.

\begin{teorema}
Пусть $\{\xi_k\}_{k=1}^\infty$ --- последовательность одинаково распределённых интегрируемых с квадратом случайных величин, наблюдаемых в опыте \GOFP.
Пусть $\xi \sim N(0,1)$.
Обозначим $\mu=M\xi_k$, $\sigma^2=D\xi_k$ ($\sigma>0$).
Проведём теперь над каждой $\xi_k$ манипуляцию, состоящую из уже знакомого нам сдвига на матожидание и новой операции - <<нормирования>> дисперсией:
$$
\xi^0_k=\frac{\xi_k-\mu}{\sigma}
$$
(Рекомендуем, кстати, читателю убедиться, что $\|\xi^0_k\|_{L_2(\Omega,\calF,P)} =1$.)
Тогда $
\bar\xi_n= \frac{ \suml_{k=1}^{n}\xi^0_k }{ \sqrt{n} } 
\xrightarrow [n\to\infty] {\mbox{слабо}} \xi
$, т.е. 
$$
P\{\bar\xi_n<x\}\xrightarrow[n\to\infty]{} \Phi(x)=\frac{1}{\sqrt{2\pi}}\intl_{-\infty}^x e^{-\frac{t^2}{2} }dx
$$
\end{teorema}
\dokvo
В доказательстве будем использовать переход к характеристическим функциям и тот факт, что характеристическая функция суммы равна произведению характеристических функций.

Сначала заметим, что $\dot\varphi_{\xi^0_k} = iM\xi^0_k = 0$, $\ddot\varphi_{\xi^0_k} = i^2 D\xi^0_k = -1$.


\begin{multline*}
\varphi_{\bar\xi_n}(t) = 
\varphi_{\frac{1}{\sqrt{n}}\sum_{k=1}^n \xi^0_k}(t) = 
\varphi_{\sum_{k=1}^n \xi^0_k} \left( \frac{t} {\sqrt{n}} \right) = 
\\ =
\prod_{k=1}^n \varphi_{\xi^0_k}\left( \frac{t} {\sqrt{n}} \right) =
\left(\varphi_{\xi^0_k}\left( \frac{t} {\sqrt{n}}\right) \right)^n =
\\ \mbox{(применяем формулу Тейлора c остаточным членом  в форме Пеано)} \\ =
\left(\varphi_{\xi^0_k}(0) + \dot\varphi_{\xi^0_k}(0) \frac{t}{\sqrt{n}} + \ddot\varphi_{\xi^0_k}(0) \frac{t^2}{2n} + o\left(\frac{1}{n}\right)\right)^n =
\\=
\left(1 + 0 \cdot \frac{t}{\sqrt{n}} - 1 \cdot \frac{t^2}{2n} + o\left(\frac{1}{n}\right)\right)^n =
\\=
\left(1 - \frac{t^2}{2n} + o\left(\frac{1}{n}\right)\right)^n
\xrightarrow[n\to\infty]{\mbox{второй замечательный предел}}
e^{-\frac{t^2}{2}} = \varphi_\xi (t)
\end{multline*}

Итак, $\varphi_{\bar\xi_n}(t) \xrightarrow[n\to\infty]{} \varphi_\xi (t)$, следовательно, 
$$
\bar\xi_n = \suml_{k=1}{n}\frac{\xi_k - \mu}{\sigma\sqrt{n}} \xrightarrow[n\to\infty]{} \xi
$$

\dokno

\section{Теорема Муавра-Лапласа}
Особо рассмотрим частный случай центральной предельной теоремы для биномиального распределения.

\begin{teorema}
Пусть $\{\xi_k\}_{k=1}^\infty$ --- последовательность одинаково биномиально с параметрами $(1,p)$ распределённых случайных величин, наблюдаемых в опыте \GOFP.
Тогда
$$
\frac{\suml_{k=1}^n \xi_k - np}{\sqrt{np(1-p)}} \xrightarrow[n\to\infty]{\mbox{слабо}}\xi \sim N(0,1)
$$
\end{teorema}
Для доказательства этой теоремы достаточно вспомнить числовые характеристики биномиального распределения.

\section{Применение теоремы Муавра-Лапласа}
Сначала заметим, что по теореме Муавра-Лапласа при достаточно большом $n$ для $\xi \sim Bi(n,p)$ имеет место приближенное равенство
\begin{equation}
P\{\xi<b\} \approx \Phi\left( \frac{b-p}{\sqrt{np(1-p)}} \right)
\end{equation}

Легко понять, что тогда
\begin{equation}\label{raznost_teorema_Muavra_Laplasa}
P\{a<\xi<b\} \approx \Phi\left( \frac{b-p}{\sqrt{np(1-p)}} \right) - \Phi\left( \frac{a-p}{\sqrt{np(1-p)}} \right)
\end{equation}

\begin{primer}
Пусть среди новорождённых частота появления мальчиков составляет $0,515$ и мы хотим узнать, с каком вероятностью среди $10000$ новорождённых мальчиков будет меньше, чем девочек.
Рассмотрим количество мальчиков --- случайную величину $\xi \sim Bi(10000; 0,515)$.
Применяем теорему Муавра-Лапласа, а именно формулу (\ref{raznost_teorema_Muavra_Laplasa}):
\begin{multline*}
P\{\xi\in[0; 10000]\} \approx
\\ \approx
\Phi\left( \frac{5000-5150}{\sqrt{10^4 \cdot 0,515 \cdot 0,485 }} \right) - \Phi\left( \frac{-5150}{\sqrt{10^4 \cdot 0,515 \cdot 0,485 }} \right) \approx
\\ \approx
\Phi(-3) - \Phi(-103) \approx 0
\end{multline*}

\end{primer}

\chapter{Типовые распределения}
\section{Распределение Парето}
\subsection{Определение}
\opred
Говорят, что случайная величина $\xi$ имеет распределение Парето с параметрами $x_0>0$ и $\alpha>0$ и пишут $\xi \sim Par(x_0,\alpha)$, если
$$
F_\xi (x) = P\{\xi < x\} = \left(1 - \left(\frac{x_0}{x}\right)^\alpha\right) \cdot \one{[x_0; +\infty)}(x)
$$

Легко видеть, что функция распределения непрерывна.
\subsection{Плотность}
$$
f_\xi (x) = \alpha\frac{x_0^\alpha}{x^{\alpha+1}} \cdot \one{[x_0; +\infty)}(x)
$$

\subsection{Математическое ожидание}
Математическое ожидание, а, следовательно, и другие моменты, могут существовать или не существовать в зависимости от значения $\alpha$.
Попробуем найти матожидание:
\begin{multline}\label{matozhidanie_Pareto}
M\xi=
\intl_{-\infty}^{+\infty}x f_\xi(x) dx =
\intl_{-\infty}^{+\infty}x \alpha \frac{x_0^\alpha}{x^{\alpha+1}} \cdot \one{[x_0; +\infty)}(x) dx =
\intl_{x_0}^{+\infty}x \alpha\frac{x_0^\alpha}{x^{\alpha+1}} dx =
\\=
\intl_{x_0}^{+\infty} \alpha\frac{x_0^\alpha}{x^\alpha} dx = 
\alpha x_0^\alpha \intl_{x_0}^{+\infty} \frac{1}{x^\alpha} dx
\end{multline}
Последний интеграл, как мы знаем из курса математического анализа, сходится при $\alpha>1$.
Следовательно, при $\alpha>1$ из формулы (\ref{matozhidanie_Pareto}) имеем
\begin{multline}\label{matozhidanie_Pareto_itog}
M\xi = 
\alpha x_0^\alpha \intl_{x_0}^{+\infty} \frac{1}{x^\alpha} dx =
\alpha x_0^\alpha \left.\left(\frac{1}{1-\alpha}\frac{1}{x^{\alpha-1}}\right)\right|_{x=x_0}^{x=+\infty} dx =
\\=
\alpha x_0^\alpha\left(0-\frac{1}{1-\alpha}\cdot\frac{1}{x_0^{\alpha-1}}\right)=
\alpha x_0^\alpha\frac{1}{\alpha-1}\cdot\frac{1}{x_0^{\alpha-1}}=
\\=
\frac{\alpha x_0^\alpha}{(\alpha-1)x_0^{\alpha-1}}=
\frac{\alpha x_0}{\alpha-1}
\end{multline}

\subsection{Прочие моменты}
Как известно, начальный момент существует или не существует одновременно с центральным.
Для начального момента порядка $k$ рассуждениями, аналогичными (\ref{matozhidanie_Pareto}), имеем
\begin{equation}\label{momenty_Pareto}
M(\xi^k)= \alpha x_0^\alpha \intl_{x_0}^{+\infty} \frac{1}{x^{\alpha-k+1}} dx
\end{equation}

А такой интеграл сходится при $\alpha-k+1 > 1$, т.е. при $\alpha > k$.
Следовательно, у распределения Парето с параметрами $x_0$ и $\alpha$ существуют $k$-ые центральный и начальный моменты тогда и только тогда, когда $\alpha > k$.

\subsection{Дисперсия}
Вооружившись формулами (\ref{matozhidanie_Pareto_itog}) и (\ref{momenty_Pareto}), посчитаем дисперсию этого распределения при $\alpha>2$:
\begin{multline}
D\xi=
M(\xi^2)-(M\xi)^2 =
\alpha x_0^\alpha \intl_{x_0}^{+\infty} \frac{1}{x^{\alpha-1}} dx - \left(\frac{\alpha x_0}{\alpha-1}\right)^2 =
\\=
\alpha x_0^\alpha \frac{1}{\alpha-2}\cdot\frac{1}{x_0^{\alpha-2}} - \frac{\alpha^2 x_0^2}{(\alpha-1)^2} = 
\frac{\alpha x_0^2}{\alpha-2} - \frac{\alpha^2 x_0^2}{(\alpha-1)^2} = 
\\=
\alpha x_0^2\left(\frac{1}{\alpha-2} - \frac{\alpha}{(\alpha-1)^2}\right) = 
\\=
\alpha x_0^2\left(\frac{(\alpha-1)^2}{(\alpha-2)(\alpha-1)^2} - \frac{\alpha^2-2\alpha}{(\alpha-2)(\alpha-1)^2}\right) =
\\= 
\alpha x_0^2\left(\frac{\alpha^2-2\alpha + 1}{(\alpha-2)(\alpha-1)^2} - \frac{\alpha^2-2\alpha}{(\alpha-2)(\alpha-1)^2}\right) = 
\frac{\alpha x_0^2}{(\alpha-2)(\alpha-1)^2}
\end{multline}

\section{Геометрическое распределение}
\subsection{Определение}
$P\{\xi=k\} = (1-p)^{k-1} p$, $k\in\N$.
\subsection{Математическое ожидание}
\begin{multline}\label{matozhidanie_geom}
M\xi =
\suml_{k=1}^\infty k (1-p)^{k-1} p =
p\suml_{k=1}^\infty k (1-p)^{k-1} =
p\suml_{k=1}^\infty \frac{d}{dp}(-(1-p)^{k}) =
\\=
p\frac{d}{dp} \suml_{k=1}^\infty (-(1-p)^{k}) =
-p\frac{d}{dp} \frac{1-p}{1-(1-p)} = 
-p\frac{d}{dp} \frac{1-p}{p} =
\\=
-p\frac{d}{dp} \left(\frac{1}{p}-1\right) = 
-p\left(-\frac{1}{p^2}\right) =
\frac{1}{p}
\end{multline}

\subsection{Дисперсия}
И снова будем применять почленное дифференцирование рядов.
\begin{multline}\label{dispersia_geom}
D\xi = 
M(\xi^2) - (M\xi)^2 =
M(\xi^2) - \frac{1}{p^2} =
\suml_{k=1}^\infty k^2 (1-p)^{k-1} p  - \frac{1}{p^2}=
\\=
p\suml_{k=1}^\infty (k^2 + k - k) (1-p)^{k-1}  - \frac{1}{p^2}=
\\=
p\suml_{k=1}^\infty k(k+1)(1-p)^{k-1} - p\suml_{k=1}^\infty k (1-p)^{k-1}  - \frac{1}{p^2}=
\\ \mbox{(значение второй суммы мы уже находили в (\ref{matozhidanie_geom}))} \\=
p\suml_{k=1}^\infty k(k+1)(1-p)^{k-1} - \frac{1}{p}  - \frac{1}{p^2}=
p\suml_{k=1}^\infty \frac{d^2}{dp^2}(1-p)^{k+1} - \frac{1}{p}  - \frac{1}{p^2}=
\\=
p\frac{d^2}{dp^2}\suml_{k=1}^\infty(1-p)^{k+1} - \frac{1}{p}  - \frac{1}{p^2}=
p\frac{d^2}{dp^2}\left((1-p)\suml_{k=1}^\infty(1-p)^{k}\right) - \frac{1}{p}  - \frac{1}{p^2}=
\\=
p\frac{d^2}{dp^2}\left((1-p)\frac{1-p}{p}\right) - \frac{1}{p}  - \frac{1}{p^2}=
p\frac{d^2}{dp^2}\left(\frac{1-2p+p^2}{p}\right) - \frac{1}{p}  - \frac{1}{p^2}=
\\=
p\frac{d^2}{dp^2}\left(\frac{1}{p}-2+p\right) - \frac{1}{p}  - \frac{1}{p^2}=
p\frac{2}{p^3} - \frac{1}{p}  - \frac{1}{p^2}=
\\=
\frac{2}{p^2} - \frac{p}{p^2}  - \frac{1}{p^2}=
\frac{1-p}{p^2}
\end{multline}

\section{Гипергеометрическое распределение}
\subsection{Определение}
$P\{\xi=k\}=\frac{C_M^k C_{N-M}^{n-k}}{C_N^n}$,
где $N$ - общеее количество элементов,
$n$ - выбираемое без возвращения количество элементов,
$k$ - требуемое количество успешных элементов.

\subsection{Математическое ожидание}
Будем, как обычно, полагать, что при $a>b$, или $a<0$, или $b<0$ $C_b^a=0$.
Это позволит нам не следить за пределами суммирования.

Далее, подготовим плацдарм в виде нескольких формул.
Во-первых, сумма вероятностей всех исходов равна 1:
\begin{equation}
\suml_{k=1}^\infty \frac{C_M^k C_{N-M}^{n-k}}{C_N^n} = 1
\end{equation}

Заменив $n$ на $n-1$; $k$ на $k-1$; $M$ на $M-1$; $N$ на $N-1$, имеем:
\begin{equation}\label{summa_gipergeom_1}
\suml_{k=1}^\infty \frac{C_{M-1}^{k-1} C_{N-M}^{n-k}}{C_{N-1}^{n-1}} = 1
\end{equation}

Заметим также, что
\begin{equation}\label{ponizhenie_C}
C_b^a =
\frac{b!}{a!(a-b)!}=
\frac{b(b-1)!}{a(a-1)!((a-1)-(b-1))!}=
\frac{b}{a}C_{b-1}^{a-1}
\end{equation}

Теперь приступаем непосредственно к штурму первого момента.

\begin{multline}
M\xi=
\suml_{k=1}^\infty k\frac{C_M^k C_{N-M}^{n-k}}{C_N^n} \stackrel{(\ref{ponizhenie_C})}{=}
\suml_{k=1}^\infty k\frac{\frac{M}{k} C_{M-1}^{k-1} C_{N-M}^{n-k}}{\frac{N}{n}C_{N-1}^{n-1}}=
\\=
\suml_{k=1}^\infty k\frac{\frac{M}{k} C_{M-1}^{k-1} C_{(N-1)-(M-1)}^{(n-1)-(k-1)}}{\frac{N}{n}C_{N-1}^{n-1}}=
\\ \mbox{(выносим за знак суммы некоторые множители, не зависящие от $k$)} \\=
\frac{Mn}{N}\suml_{k=1}^\infty k\frac{\frac{1}{k} C_{M-1}^{k-1} C_{(N-1)-(M-1)}^{(n-1)-(k-1)}}{C_{N-1}^{n-1}}=
\\=
\frac{Mn}{N}\suml_{k=1}^\infty \frac{ C_{M-1}^{k-1} C_{(N-1)-(M-1)}^{(n-1)-(k-1)}}{C_{N-1}^{n-1}}\stackrel{(\ref{summa_gipergeom_1})}{=}
\frac{Mn}{N}
\end{multline}

\subsection{Дисперсия}
Здесь мы снова применим приём, знакомый по формуле (\ref{dispersia_geom}), а именно --- разбитие суммы с квадратом на две.
Считаем второй начальный момент:
\begin{multline}
M(\xi^k) =
\suml_{k=1}^\infty k^2\frac{C_M^k C_{N-M}^{n-k}}{C_N^n}=
\suml_{k=1}^\infty k(k-1)\frac{C_M^k C_{N-M}^{n-k}}{C_N^n} + \suml_{k=1}^\infty k\frac{C_M^k C_{N-M}^{n-k}}{C_N^n} =
\\ \mbox{(вторую сумму мы считали парой строк выше, чем и воспользуемся)} \\=
\suml_{k=1}^\infty k(k-1)\frac{C_M^k C_{N-M}^{n-k}}{C_N^n} + \frac{Mn}{N} \stackrel{(\ref{ponizhenie_C})}{=}
\suml_{k=1}^\infty k(k-1)\frac{\frac{M}{k} C_{M-1}^{k-1} C_{N-M}^{n-k}}{\frac{N}{n}C_{N-1}^{n-1}} + \frac{Mn}{N} \stackrel{(\ref{ponizhenie_C})}{=}
\\=
\suml_{k=1}^\infty k(k-1)\frac{\frac{M}{k} \cdot \frac{M-1}{k-1} C_{M-2}^{k-2} C_{N-M}^{n-k}}{\frac{N}{n}\cdot\frac{N-1}{n-1} C_{N-2}^{n-2}} + \frac{Mn}{N} =
\\ \mbox{(сокращаем множители k(k-1))} \\=
\suml_{k=1}^\infty \frac{M (M-1) C_{M-2}^{k-2} C_{N-M}^{n-k}}{\frac{N}{n}\cdot\frac{N-1}{n-1} C_{N-2}^{n-2}} + \frac{Mn}{N} =
\\ \mbox{(выносим за скобки некоторые множители, не содержащие k)} \\=
\frac{M (M-1) n (n-1)}{N(N-1)}\suml_{k=1}^\infty \frac{ C_{M-2}^{k-2} C_{N-M}^{n-k}}{ C_{N-2}^{n-2}} + \frac{Mn}{N} \stackrel{\ref{summa_gipergeom_1}}{=}
\\=
\frac{M (M-1) n (n-1)}{N(N-1)} + \frac{Mn}{N}
\end{multline}

Теперь считаем дисперсию --- исключительно алгебраическое времяпровождение:
\begin{multline}
D\xi =
M(\xi^2)-(M\xi)^2 = 
\frac{M (M-1) n (n-1)}{N(N-1)} + \frac{Mn}{N} - \frac{M^2 n^2}{N^2} =
\\=
\frac{Mn}{N} \left(  \frac{(M-1)(n-1)}{N-1} + 1 - \frac{M n}{N}  \right) =
\\=
\frac{Mn}{N} \left(  \frac{Mn-M-n+1}{N-1} + 1 - \frac{M n}{N}  \right) =
\\=
\frac{Mn}{N} \left(  \frac{MnN-MN-nN+N}{N(N-1)} + 1 - \frac{M nN - Mn}{N(N-1)}  \right) =
\\=
\frac{Mn}{N} \left(  \frac{MnN - MN - nN + N - MnN + Mn}{N(N-1)} + 1 \right) =
\\=
\frac{Mn}{N} \left(  \frac{- MN - nN + N + Mn}{N(N-1)} + 1 \right) =
\\=
\frac{Mn}{N} \left(  \frac{- MN - nN + N + Mn + N^2 - N }{N(N-1)} \right) =
\\=
\frac{Mn}{N} \left(  \frac{- MN - nN + Mn + N^2 }{N(N-1)} \right) =
\\=
\frac{Mn}{N} \left(  \frac{n(M-N) -N (M-N)}{N(N-1)} \right) =
\\=
\frac{Mn}{N} \left(  \frac{(n-N)(M-N)}{N(N-1)} \right) =
\frac{Mn(n-N)(M-N)}{N^2(N-1)}
\end{multline}

\section{Гамма-распределение}

\subsection{Определение}

Говорят, что $\xi \sim \Gamma(\lambda,\nu)$, если 
\begin{equation}\label{opred_Gamma_raspr}
f_\xi( x) =\frac{\lambda ^{\nu}}{\Gamma( \nu) } e^{ -\lambda x }x^{\nu-1} \cdot \one{[0; +\infty)}(x)
\end{equation}

\subsection{Матожидание}

\begin{multline}
M\xi=
\intl_{- \infty  }^{+ \infty  } x  f_\xi( x)   dx =
\intl_{0 }^{+ \infty  } x  \frac{\lambda ^{\nu}}{\Gamma( \nu) } e^{ -\lambda x }x^{\nu-1}   dx =
\\\mbox{( т. к. $\Gamma(\nu +1) =\nu\Gamma( \nu)) $}\\=
\intl_{0 }^{+ \infty  } x  \frac{\lambda ^{\nu+1}\nu}{\lambda \Gamma( \nu+1) } e^{ -\lambda x }x^{\nu-1}   dx =
\intl_{0 }^{+ \infty  } \frac{\lambda ^{\nu+1}\nu}{\lambda \Gamma( \nu+1) } e^{ -\lambda x }x^{\nu+1-1}   dx =
\\=
\frac{\nu}{\lambda }\intl_{0 }^{+ \infty  } \frac{\lambda ^{\nu+1}}{ \Gamma( \nu+1) } e^{ -\lambda x }x^{( \nu+1) -1}   dx =
\\=
\frac{\nu}{\lambda }\intl_{- \infty  }^{+ \infty  } \frac{\lambda ^{\nu+1}}{ \Gamma( \nu+1) } e^{ -\lambda x }x^{( \nu+1) -1} \cdot \one{[0; +\infty)}(x)  dx =
\\  \mbox{( но это - интеграл по всему пространству от плотности }\\\mbox{ распределения $\Gamma( \lambda ,\nu+1) $(\ref{opred_Gamma_raspr}), который равен 1 )}\\=
\frac{\nu}{\lambda }
\end{multline}

\subsection{Дисперсия}

Считаем матожидание квадрата:
\begin{multline}
M(\xi^2)=
\intl_{- \infty  }^{+ \infty  } x^2  f_\xi( x)   dx =
\intl_{0 }^{+ \infty  } x^2  \frac{\lambda ^{\nu}}{\Gamma( \nu) } e^{ -\lambda x }x^{\nu-1}   dx =
\\\mbox{( т. к. $\Gamma(\nu +1) =\nu\Gamma( \nu)) $}\\=
\intl_{0 }^{+ \infty  } x^2  \frac{\lambda ^{\nu+1}\nu}{\lambda \Gamma( \nu+1) } e^{ -\lambda x }x^{\nu-1}   dx =
\intl_{0 }^{+ \infty  } x^2  \frac{\lambda ^{\nu+2}\nu(\nu+1)}{\lambda^2 \Gamma( \nu+2) } e^{ -\lambda x }x^{\nu-1}   dx =
\\=
\intl_{0 }^{+ \infty  }  \frac{\lambda ^{\nu+2}\nu(\nu+1)}{\lambda^2 \Gamma( \nu+2) } e^{ -\lambda x }x^{(\nu+2)-1}   dx =
\\=
\frac{\nu(\nu+1)}{\lambda^2}\intl_{0 }^{+ \infty  }  \frac{\lambda ^{\nu+2}}{\Gamma( \nu+2) } e^{ -\lambda x }x^{(\nu+2)-1}   dx =
\\=
\frac{\nu(\nu+1)}{\lambda^2}\intl_{-\infty }^{+ \infty  }  \frac{\lambda ^{\nu+2}}{\Gamma( \nu+2) } e^{ -\lambda x }x^{(\nu+2)-1} \cdot \one{[0; +\infty)}(x)   dx =
\\  \mbox{( но это --- интеграл по всему пространству от плотности }\\\mbox{ распределения $\Gamma( \lambda ,\nu+1) $(\ref{opred_Gamma_raspr}), который равен 1 )}\\=
\frac{\nu(\nu+1)}{\lambda^2}
\end{multline}

Тогда
\begin{multline}
D\xi=M( \xi^{2}) -( M\xi) ^{2}=
\frac{\nu(\nu+1)}{\lambda^2}  -   \left( \frac{\nu}{\lambda } \right)  ^{2}=
\frac{\nu^{2}-\nu-\nu^{2}}{\lambda ^{2}}=
\frac{\nu}{\lambda ^{2}}
\end{multline}

\section{Нормальное распределение}

\subsection{Определение}
Говорят, что $\xi \sim N(\mu, \sigma)$, если
\begin{equation}
f_\xi (x) = \frac{1}{ \sqrt{2 \pi }\sigma }e^{ \frac{-(x-\mu)^2}{2\sigma^2} }
\end{equation}

\subsection{Матожидание}

\begin{multline}
M\xi =
\intl_{-\infty }^{\infty } x \frac{1}{ \sqrt{2 \pi }\sigma }e^{ \frac{-(x-\mu)^2}{2\sigma^2} } dx =
\\\mbox{( положим $t=x-\mu$, тогда $dx=dt$ )}\\=
\intl_{-\infty }^{\infty } (t+\mu) \frac{1}{ \sqrt{2 \pi }\sigma }e^{ \frac{-t^2}{2\sigma^2} } dt =
\intl_{-\infty }^{\infty } t \frac{1}{ \sqrt{2 \pi }\sigma }e^{ \frac{-t^2}{2\sigma^2} } dt + \intl_{-\infty }^{\infty } \mu \frac{1}{ \sqrt{2 \pi }\sigma }e^{ \frac{-t^2}{2\sigma^2} } dt =
\\\mbox{( левый интеграл - интеграл от нечётной функции }\\\mbox{по всему пространству, он равен нулю )}\\=
\intl_{-\infty }^{\infty } \mu \frac{1}{ \sqrt{2 \pi }\sigma }e^{ \frac{-t^2}{2\sigma^2} } dt =
 \mu \intl_{-\infty }^{\infty }\frac{1}{ \sqrt{2 \pi }\sigma }e^{ \frac{-t^2}{2\sigma^2} } dt =
\\\mbox{( это интеграл от плотности по всему пространству, он равен 1 )}\\=
\mu
\end{multline}

\subsection{Дисперсия}
В отличие от других распределений, здесь мы будем считать дисперсию по определению.

Напомним читателю, что в курсе математического анализа вычислялся интеграл Пуассона:
\begin{equation}\label{integral_Puassona}
 \intl_{-\infty }^{\infty } e^{ -x^2 } dx =  \sqrt{ \pi }
\end{equation}

Вычислим теперь два очень похожих на него интеграла:

\begin{multline}\label{integral_Puassona_y}
 \int y e^{ -y^2 } dy =
\\\mbox{( замена: $t = -y^2$, $dt = -2ydy$ )}\\=
-\frac{1}{2} \int e^t dt =
-\frac{1}{2} e^t =
-\frac{1}{2} e^{-y^2}
\end{multline}

\begin{multline}\label{integral_Puassona_y2}
 \intl_{-\infty }^{\infty } y^2 e^{ -y^2 } dy =
\\\mbox{( по частям: $u=y$, $du=dy$, $dv = y e^{ -y^2 } dy$, }\\\mbox{ $v= -\frac{1}{2} e^{-y^2}$ по формуле (\ref{integral_Puassona_y}))}\\=
 \left( \left.  -\frac{1}{2} ye^{-y^2}    \right)  \right|_{ y =  -\infty }^{   \infty  } - \intl_{-\infty }^{\infty } -\frac{1}{2} e^{-y^2} dy =
 \frac{1}{2} \intl_{-\infty }^{\infty }  e^{-y^2} dy =
\\\mbox{( а это --- интеграл Пуассона (\ref{integral_Puassona}) )}\\=
\frac{ \sqrt{ \pi } }{2}
\end{multline}

Теперь всё готово к штурму непосредственно дисперсии.

\begin{multline}
D\xi = M\left((\xi-M\xi)^2\right) =
\intl_{-\infty }^{\infty } (x-\mu)^2 \frac{1}{ \sqrt{2 \pi }\sigma }e^{ \frac{-(x-\mu)^2}{2\sigma^2} } dx =
\\=
\sigma\sqrt{2}\intl_{-\infty }^{\infty } (x-\mu)^2 \frac{1}{ 2\sqrt{ \pi }\sigma^2 }e^{ \frac{-(x-\mu)^2}{2\sigma^2} } dx =
\\\mbox{( положим $y=\frac{x-\mu}{\sigma\sqrt{2}}$, тогда $dx = \sigma \sqrt{2} dy$ )}\\=
\sigma\sqrt{2}\intl_{-\infty }^{\infty } y^2 \frac{1}{ 2\sqrt{ \pi }\sigma^2 }e^{ -y^2}  \sigma \sqrt{2} dy =
2\sigma^2 \frac{1}{ \sqrt{ \pi }} \intl_{-\infty }^{\infty } y^2 e^{ -y^2} dy =
\\\mbox{( но это --- интеграл вида (\ref{integral_Puassona_y2}) )}\\=
2\sigma^2 \frac{1}{ \sqrt{ \pi }} \frac{ \pi }{2}=
\sigma^2
\end{multline}

\section{Равномерное распределение}

\subsection{Определение}
\begin{equation}
	f_\xi(x) = \frac{1}{b-a} \one{[a;b]}(x)
\end{equation}
\subsection{Матожидание}

\begin{multline}
M\xi =  \intl_{-\infty }^{\infty } xf_\xi(x) dx =
\intl_{a }^{b } x \frac{1}{b-a} dx =
\\=
\frac{1}{b-a} \left.  \left( \frac{x^2}{2} \right)   \right|_{ x=a}^{ x=b}=
\frac{b^2-a^2}{2(b-a)}=
\frac{(b-a)(b+a)}{2(b-a)}=
\frac{a+b}{2}
\end{multline}

\subsection{Дисперсия}
\begin{multline}
    M( \xi ^2) = 
    \intl_{-\infty }^{\infty } x^2 \frac{1}{b-a}dx =
    \frac{1}{b-a} \intl_{-\infty }^{\infty } x^2 dx =
    \\=
    \frac{1}{b-a}\left. \left( \frac{x^3}{3} \right)  \right|_{ x=a}^{ x=b} = 
    \frac{1}{b-a} \left( \frac{b^3}{3} - \frac{a^3}{3}\right) =
    \\=
    \frac{1}{b-a} \left( \frac{b^3 - a^3}{3} \right) = 
    \frac{1}{b-a} \left( \frac{(b-a)(a^2+ab+b^2)}{3} \right) = 
    \frac{a^2+ab+b^2}{3}
\end{multline}

\begin{multline}
	D\xi =
	M(\xi^2)-(M\xi)^2 = 
	\frac{a^2+ab+b^2}{3} - \left( \frac{a+b}{2} \right)^2  =
	\\=
	\frac{a^2+ab+b^2}{3} - \frac{a^2+2ab+b^2}{4} =  
	\frac{4a^2+4ab+4b^2}{12} - \frac{3a^2+6ab+3b^2}{12} = 
	\\= 
	\frac{4a^2+4ab+4b^2-3a^2-6ab-3b^2}{12}=  
	\frac{a^2 -2ab + b^2 }{12}=  
	\frac{(a-b)^2}{12}  
\end{multline}


\section{распределение}

\subsection{Определение}

\subsection{Матожидание}

\subsection{Дисперсия}

\section{распределение}

\subsection{Определение}

\subsection{Матожидание}

\subsection{Дисперсия}

\section{распределение}

\subsection{Определение}

\subsection{Матожидание}

\subsection{Дисперсия}

